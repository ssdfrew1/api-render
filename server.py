import os
import asyncio
from fastapi import FastAPI
import uvicorn
from aiogram import Bot, Dispatcher, types
from huggingface_hub import AsyncInferenceClient

# –î–∞–Ω–Ω—ã–µ
TOKEN = os.getenv("TELEGRAM_TOKEN")
HF_TOKEN = os.getenv("HF_TOKEN")

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
bot = Bot(token=TOKEN)
dp = Dispatcher()
client = AsyncInferenceClient("Qwen/Qwen2.5-72B-Instruct", token=HF_TOKEN)
app = FastAPI()

@app.get("/")
async def health_check():
    return {"status": "ok"}

@dp.message()
async def chat_handler(message: types.Message):
    if not message.text: return
    msg = await message.answer("ü§ñ –°–µ–∫—É–Ω–¥—É...")
    try:
        response_text = ""
        # –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π –≤—ã–∑–æ–≤ (—Å–Ω–∞—á–∞–ª–∞ await, –ø–æ—Ç–æ–º async for)
        stream = await client.chat_completion(
            messages=[
                {"role": "system", "content": "–¢—ã ‚Äî –∫—Ä—É—Ç–æ–π –ò–ò-–∫–æ–¥–µ—Ä. –û—Ç–≤–µ—á–∞–π –Ω–∞ —Ä—É—Å—Å–∫–æ–º."},
                {"role": "user", "content": message.text}
            ],
            max_tokens=1000, stream=True
        )
        async for token in stream:
            response_text += token.choices[0].delta.content or ""
        
        await msg.edit_text(response_text if response_text.strip() else "–ü—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç.")
    except Exception as e:
        await msg.edit_text(f"–û—à–∏–±–∫–∞: {e}")

async def run_bot():
    print("–ó–∞–ø—É—Å–∫ –±–æ—Ç–∞...")
    await dp.start_polling(bot)

@app.on_event("startup")
async def startup_event():
    # –ó–∞–ø—É—Å–∫–∞–µ–º –±–æ—Ç–∞ –∫–∞–∫ —Ñ–æ–Ω–æ–≤—É—é –∑–∞–¥–∞—á—É, —á—Ç–æ–±—ã –Ω–µ –±–ª–æ–∫–∏—Ä–æ–≤–∞—Ç—å –ø–æ—Ä—Ç
    asyncio.create_task(run_bot())

if __name__ == "__main__":
    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä –ü–ï–†–í–´–ú. –ü–æ—Ä—Ç 10000 ‚Äî —Å—Ç–∞–Ω–¥–∞—Ä—Ç –¥–ª—è Render
    port = int(os.environ.get("PORT", 10000))
    uvicorn.run(app, host="0.0.0.0", port=port)
